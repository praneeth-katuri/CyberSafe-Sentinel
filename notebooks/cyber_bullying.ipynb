{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install contractions"
      ],
      "metadata": {
        "id": "uhNv-7FNN2CZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pickle\n",
        "import string\n",
        "import contractions\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "from sklearn.utils import resample\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score,\n",
        "    confusion_matrix,\n",
        "    classification_report,\n",
        ")\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import lightgbm as lgb"
      ],
      "metadata": {
        "id": "ISbocBDb9BDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.Data Collection"
      ],
      "metadata": {
        "id": "mDJZ_Cv-p_-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' Loading Dataset 1'''\n",
        "train1 = pd.read_csv('/content/drive/MyDrive/train_1.csv')\n",
        "print('----- Train Set 1 -----')\n",
        "train1.head()"
      ],
      "metadata": {
        "id": "ncf4yUKIAxdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test1 = pd.read_csv('/content/drive/MyDrive/test_1.csv')\n",
        "print('----- Test Set 1 -----')\n",
        "test1.head()"
      ],
      "metadata": {
        "id": "ZRWNNlQwAnNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' Loading dataset 2 '''\n",
        "df = pd.read_csv('/content/drive/MyDrive/dataset2.csv')\n",
        "print('----- Dataset 2 -----')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "0OxHg3gv9GkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[['index','oh_label','Text']]\n",
        "df.head()"
      ],
      "metadata": {
        "id": "QAR1dismCZOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' Renaming Column names to follow a single naming convention '''\n",
        "# Before renaming the Columns\n",
        "print(\"\\nBefore modifying column names:\\n\", df.columns)\n",
        "\n",
        "df.rename(columns = {'index':'id','oh_label':'label','Text':'tweet'}, inplace = True)\n",
        "\n",
        "# After renaming the columns\n",
        "print(\"\\nAfter modifying first column:\\n\", df.columns)"
      ],
      "metadata": {
        "id": "U86JJX40_MT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Spliting the dataset 2 into training and testing dataset'''\n",
        "\n",
        "train2, test2 = train_test_split(df, test_size=0.3, random_state=10, shuffle=True)\n",
        "\n",
        "train2 = train2[['id', 'label', 'tweet']]\n",
        "test2 = test2[['id', 'tweet']]"
      ],
      "metadata": {
        "id": "1NsZUATL_RS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('----- Train Set 2 -----')\n",
        "train2"
      ],
      "metadata": {
        "id": "zjgWQi9WCnQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('----- Test Set 2 -----')\n",
        "print(test2)"
      ],
      "metadata": {
        "id": "XOIn2vAqCpmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merging two Train Data Sets\n",
        "train = pd.concat([train1, train2], ignore_index = True)\n",
        "print(train)"
      ],
      "metadata": {
        "id": "lVDmUoQj_ZZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['label'].value_counts()"
      ],
      "metadata": {
        "id": "WWAwpX3EC6bc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merging two Test Data Sets\n",
        "test = pd.concat([test1,test2], ignore_index = True)\n",
        "print(test)"
      ],
      "metadata": {
        "id": "_Rh7dcrFC14C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.Data Preprocessing"
      ],
      "metadata": {
        "id": "uqFhmUjXrL8m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Cleaning the Data"
      ],
      "metadata": {
        "id": "D3xgLVRmtO7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(df, text_field):\n",
        "    # Convert text to lowercase\n",
        "    df[text_field] = df[text_field].str.lower()\n",
        "\n",
        "    # Remove full URLs\n",
        "    df[text_field] = df[text_field].apply(lambda elem: re.sub(r\"\\w+:\\/\\/\\S+\", \"\", elem))\n",
        "\n",
        "    # Remove strings starting with 'http'\n",
        "    df[text_field] = df[text_field].apply(lambda elem: re.sub(r'http\\S+', '', elem))\n",
        "\n",
        "    # Remove square brackets content\n",
        "    df[text_field] = df[text_field].apply(lambda elem: re.sub(r'\\[.*?\\]', '', elem))\n",
        "\n",
        "    # Remove parentheses content\n",
        "    df[text_field] = df[text_field].apply(lambda elem: re.sub(r'\\(.*?\\)', '', elem))\n",
        "\n",
        "    # Remove hashtags\n",
        "    df[text_field] = df[text_field].apply(lambda elem: re.sub(r'#', ' ', elem))\n",
        "\n",
        "    # Remove mentions\n",
        "    df[text_field] = df[text_field].apply(lambda elem: re.sub(r'@[^\\s]+', '', elem))\n",
        "\n",
        "    # Remove 'rt' at the beginning of the string\n",
        "    df[text_field] = df[text_field].apply(lambda elem: re.sub(r'^rt', '', elem))\n",
        "\n",
        "    # Fix contractions\n",
        "    df[text_field] = df[text_field].apply(lambda elem: contractions.fix(elem))\n",
        "\n",
        "    # Remove punctuations\n",
        "    df[text_field] = df[text_field].apply(lambda elem: re.sub('[%s]' % re.escape(string.punctuation), ' ', elem))\n",
        "\n",
        "    # Remove digits\n",
        "    df[text_field] = df[text_field].apply(lambda elem: re.sub(r'\\w*\\d\\w*', '', elem))\n",
        "\n",
        "    # Remove new line characters\n",
        "    df[text_field] = df[text_field].apply(lambda elem: re.sub(r'\\n', ' ', elem))\n",
        "    df[text_field] = df[text_field].apply(lambda elem: re.sub(r'\\\\n', ' ', elem))\n",
        "\n",
        "    # Remove quotation marks\n",
        "    df[text_field] = df[text_field].apply(lambda elem: re.sub(r\"[''\\\"“”‘’…]\", '', elem))\n",
        "\n",
        "    # Remove HTML attributes\n",
        "    df[text_field] = df[text_field].apply(lambda elem: re.sub(r'<[^>]+>', '', elem))\n",
        "\n",
        "    # Remove non-English languages\n",
        "    df[text_field] = df[text_field].apply(lambda elem: re.sub(r'[^a-zA-Z\\s]', '', elem))\n",
        "\n",
        "    # Remove emojis and symbols\n",
        "    df[text_field] = df[text_field].apply(lambda elem: re.compile(\"[\"\n",
        "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                               u\"\\U00002500-\\U00002BEF\"\n",
        "                               u\"\\U00002702-\\U000027B0\"\n",
        "                               u\"\\U00002702-\\U000027B0\"\n",
        "                               u\"\\U000024C2-\\U0001F251\"\n",
        "                               u\"\\U0001f926-\\U0001f937\"\n",
        "                               u\"\\U00010000-\\U0010ffff\"\n",
        "                               u\"\\u2640-\\u2642\"\n",
        "                               u\"\\u2600-\\u2B55\"\n",
        "                               u\"\\u200d\"\n",
        "                               u\"\\u23cf\"\n",
        "                               u\"\\u23e9\"\n",
        "                               u\"\\u231a\"\n",
        "                               u\"\\ufe0f\"  # dingbats\n",
        "                               u\"\\u3030\"\n",
        "                               \"]+\", flags=re.UNICODE).sub(r'', elem))\n",
        "\n",
        "    # Strip whitespace\n",
        "    df[text_field] = df[text_field].str.strip()\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "ZIXGoVtguCJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Upsampling"
      ],
      "metadata": {
        "id": "hdrHeh_3tYKv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Data Cleaning and upsampling to balance the class distribution'''\n",
        "test_clean = clean_text(test, \"tweet\")\n",
        "train_clean = clean_text(train, \"tweet\")\n",
        "\n",
        "train_majority = train_clean[train_clean.label==0]\n",
        "train_minority = train_clean[train_clean.label==1]\n",
        "train_minority_upsampled = resample(train_minority,\n",
        "                                 replace=True,\n",
        "                                 n_samples=len(train_majority),\n",
        "                                 random_state=123)\n",
        "train_upsampled = pd.concat([train_minority_upsampled, train_majority])\n",
        "train_upsampled['label'].value_counts()\n",
        "\n",
        "train_upsampled"
      ],
      "metadata": {
        "id": "6R7Ih76m_kyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.Data Visualisation"
      ],
      "metadata": {
        "id": "w13qBnB0uOI-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 WordCloud Before Upsampling"
      ],
      "metadata": {
        "id": "lb7YnPwTupJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Data Visualisation using WordCloud (use jupyter notebook for Visualisation)'''\n",
        "fig, axs = plt.subplots(1,2 , figsize=(16,8))\n",
        "text_pos = \" \".join(train_clean['tweet'][train.label == 0])\n",
        "text_neg = \" \".join(train_clean['tweet'][train.label == 1])\n",
        "train_cloud_pos = WordCloud(collocations = False, background_color = 'white').generate(text_pos)\n",
        "train_cloud_neg = WordCloud(collocations = False, background_color = 'black').generate(text_neg)\n",
        "axs[0].imshow(train_cloud_pos, interpolation='bilinear')\n",
        "axs[0].axis('off')\n",
        "axs[0].set_title('Non-Hate Comments')\n",
        "axs[1].imshow(train_cloud_neg, interpolation='bilinear')\n",
        "axs[1].axis('off')\n",
        "axs[1].set_title('Hate Comments')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "me1RcRtc_hAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 Histogram (Class distribution BEFORE and AFTER Upsampling)"
      ],
      "metadata": {
        "id": "82tQKx0mu1U1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''histogram to show class distribution before and after upsampling'''\n",
        "plt.figure(figsize=(16,8))\n",
        "sns.set_style('darkgrid')\n",
        "sns.histplot(data = train['label'], color='black', legend=True)\n",
        "sns.histplot(data = train_upsampled['label'], color = 'orange', legend=True)\n",
        "plt.legend(['Initial_Data', 'Resampled_Data'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gxVq0nJy_sL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3 WordCloud after Upsampling"
      ],
      "metadata": {
        "id": "JAAOCGkwvQFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('--------------After Upsampling the Minority Class---------------')\n",
        "\n",
        "fig, axs = plt.subplots(1,2 , figsize=(16,8))\n",
        "text_pos = \" \".join(train_upsampled['tweet'][train.label == 0])\n",
        "text_neg = \" \".join(train_upsampled['tweet'][train.label == 1])\n",
        "train_cloud_pos = WordCloud(collocations = False, background_color = 'white').generate(text_pos)\n",
        "train_cloud_neg = WordCloud(collocations = False, background_color = 'black').generate(text_neg)\n",
        "axs[0].imshow(train_cloud_pos, interpolation='bilinear')\n",
        "axs[0].axis('off')\n",
        "axs[0].set_title('Non-Hate Comments')\n",
        "axs[1].imshow(train_cloud_neg, interpolation='bilinear')\n",
        "axs[1].axis('off')\n",
        "axs[1].set_title('Hate Comments')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7LrNxkjD_uG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.Feature Representation"
      ],
      "metadata": {
        "id": "2UTR2IMXvqHS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1 CountVectorizer (CV)"
      ],
      "metadata": {
        "id": "b7wg3f_vxAYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv = CountVectorizer(max_features = 2000)\n",
        "X = cv.fit_transform(train_upsampled['tweet']).toarray()"
      ],
      "metadata": {
        "id": "2lNrOZp1AJCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "id": "p5ksD60WxgJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting the 'label' column as the target variable\n",
        "y = train_upsampled['label'].values\n",
        "y = y.reshape(-1, 1)\n",
        "y_df = pd.DataFrame(y)\n",
        "y = np.array(y_df[0])"
      ],
      "metadata": {
        "id": "SKUvmz5N_0mh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.Model Selection"
      ],
      "metadata": {
        "id": "L7JlaFi0zO3K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nb = MultinomialNB()"
      ],
      "metadata": {
        "id": "oOOfMhsazS4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm = SVC(kernel='linear')"
      ],
      "metadata": {
        "id": "BRlitFYQzzHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression()"
      ],
      "metadata": {
        "id": "0ii2-r8oz1pQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)"
      ],
      "metadata": {
        "id": "yS05CNvyz_Vk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm = lgb.LGBMClassifier()"
      ],
      "metadata": {
        "id": "8oyiAJWp0Se3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7.Model Training"
      ],
      "metadata": {
        "id": "TQPRKfeT07z9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.1 Spliting the Dataset"
      ],
      "metadata": {
        "id": "fHdQnihQ1Eqp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 1)"
      ],
      "metadata": {
        "id": "gam96NErL3YJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.2 Training the Model"
      ],
      "metadata": {
        "id": "6wf9MU1t1oCf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Naive Bayes\n",
        "nb.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "W3fGKKHq-kDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM\n",
        "svm.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "T8HCvk1J-n8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression\n",
        "lr.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "oe1uiQsB-qiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest\n",
        "rf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "fMVBllYr-ukv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LightGBM\n",
        "lgbm.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "LZYpZgNy-wtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.3 Model Evaluation (Training)\n",
        "\n"
      ],
      "metadata": {
        "id": "_tPniB1G1yIV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Naive Bayes Classifier"
      ],
      "metadata": {
        "id": "7VLFaFZZQJyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nb_train_pred = nb.predict(X_train)\n",
        "nb_train_pred_proba = nb.predict_proba(X_train)[:, 1]\n",
        "nb_train_accuracy = accuracy_score(y_train, nb_train_pred)\n",
        "nb_train_precision = precision_score(y_train, nb_train_pred)\n",
        "nb_train_recall = recall_score(y_train, nb_train_pred)\n",
        "nb_train_f1 = f1_score(y_train, nb_train_pred)\n",
        "nb_train_roc_auc = roc_auc_score(y_train, nb_train_pred_proba)\n",
        "nb_train_cm = confusion_matrix(y_train, nb_train_pred)\n",
        "nb_train_report = classification_report(y_train, nb_train_pred)\n",
        "\n",
        "\n",
        "print(\"Naive Bayes:\")\n",
        "print(\"Training Metrics:\")\n",
        "print(f\"Accuracy: {nb_train_accuracy:.4f}\")\n",
        "print(f\"Precision: {nb_train_precision:.4f}\")\n",
        "print(f\"Recall: {nb_train_recall:.4f}\")\n",
        "print(f\"F1-score: {nb_train_f1:.4f}\")\n",
        "print(f\"ROC AUC Score: {nb_train_roc_auc:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(nb_train_cm)\n",
        "print(\"Training Classification Report:\")\n",
        "print(nb_train_report)"
      ],
      "metadata": {
        "id": "tleEIz9l4Q70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Support Vector Machine"
      ],
      "metadata": {
        "id": "35nU9ohzQFBG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jy7qUe7LxRO0"
      },
      "outputs": [],
      "source": [
        "svm_train_pred = svm.predict(X_train)\n",
        "svm_test_pred_proba = svm.predict_proba(X_test)[:, 1]\n",
        "svm_train_accuracy = accuracy_score(y_train, svm_train_pred)\n",
        "svm_train_precision = precision_score(y_train, svm_train_pred)\n",
        "svm_train_recall = recall_score(y_train, svm_train_pred)\n",
        "svm_train_f1 = f1_score(y_train, svm_train_pred)\n",
        "svm_train_roc_auc = roc_auc_score(y_train, svm_train_pred_proba)\n",
        "svm_train_cm = confusion_matrix(y_train, svm_train_pred)\n",
        "svm_train_report = classification_report(y_train, svm_train_pred)\n",
        "\n",
        "print(\"SVM:\")\n",
        "print(\"Training Metrics:\")\n",
        "print(f\"Accuracy: {svm_train_accuracy:.4f}\")\n",
        "print(f\"Precision: {svm_train_precision:.4f}\")\n",
        "print(f\"Recall: {svm_train_recall:.4f}\")\n",
        "print(f\"F1-score: {svm_train_f1:.4f}\")\n",
        "print(f\"ROC AUC Score: {svm_train_roc_auc:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(svm_train_cm)\n",
        "print(\"Training Classification Report:\")\n",
        "print(svm_train_report)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Logistic Regression"
      ],
      "metadata": {
        "id": "t2iyQT2mQCk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_train_pred = lr.predict(X_train)\n",
        "lr_train_pred_proba = lr.predict_proba(X_train)[:, 1]\n",
        "lr_train_accuracy = accuracy_score(y_train, lr_train_pred)\n",
        "lr_train_precision = precision_score(y_train, lr_train_pred)\n",
        "lr_train_recall = recall_score(y_train, lr_train_pred)\n",
        "lr_train_f1 = f1_score(y_train, lr_train_pred)\n",
        "lr_train_roc_auc = roc_auc_score(y_train, lr_train_pred_proba)\n",
        "lr_train_cm = confusion_matrix(y_train, lr_train_pred)\n",
        "lr_train_report = classification_report(y_train, lr_train_pred)\n",
        "\n",
        "print(\"Logistic Regression:\")\n",
        "print(\"Training Metrics:\")\n",
        "print(f\"Accuracy: {lr_train_accuracy:.4f}\")\n",
        "print(f\"Precision: {lr_train_precision:.4f}\")\n",
        "print(f\"Recall: {lr_train_recall:.4f}\")\n",
        "print(f\"F1-score: {lr_train_f1:.4f}\")\n",
        "print(f\"ROC AUC Score: {lr_train_roc_auc:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(lr_train_cm)\n",
        "print(\"Training Classification Report:\")\n",
        "print(lr_train_report)"
      ],
      "metadata": {
        "id": "8fIl_Ivt4l-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Random Forest"
      ],
      "metadata": {
        "id": "7YgaOqixQAPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_train_pred = rf.predict(X_train)\n",
        "rf_train_pred_proba = rf.predict_proba(X_train)[:, 1]\n",
        "rf_train_accuracy = accuracy_score(y_train, rf_train_pred)\n",
        "rf_train_precision = precision_score(y_train, rf_train_pred)\n",
        "rf_train_recall = recall_score(y_train, rf_train_pred)\n",
        "rf_train_f1 = f1_score(y_train, rf_train_pred)\n",
        "rf_train_roc_auc = roc_auc_score(y_train, rf_train_pred_proba)\n",
        "rf_train_cm = confusion_matrix(y_train, rf_train_pred)\n",
        "rf_train_report = classification_report(y_train, rf_train_pred)\n",
        "\n",
        "print(\"Random Forest:\")\n",
        "print(\"Training Metrics:\")\n",
        "print(f\"Accuracy: {rf_train_accuracy:.4f}\")\n",
        "print(f\"Precision: {rf_train_precision:.4f}\")\n",
        "print(f\"Recall: {rf_train_recall:.4f}\")\n",
        "print(f\"F1-score: {rf_train_f1:.4f}\")\n",
        "print(f\"ROC AUC Score: {rf_train_roc_auc:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(rf_train_cm)\n",
        "print(\"Training Classification Report:\")\n",
        "print(rf_train_report)"
      ],
      "metadata": {
        "id": "tW1pf4054pWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* LightGBM"
      ],
      "metadata": {
        "id": "jc4oXXpPP-Ha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_train_pred = lgbm.predict(X_train)\n",
        "lgbm_train_pred_proba = lgbm.predict_proba(X_train)[:, 1]\n",
        "lgbm_train_accuracy = accuracy_score(y_train, lgbm_train_pred)\n",
        "lgbm_train_precision = precision_score(y_train, lgbm_train_pred)\n",
        "lgbm_train_recall = recall_score(y_train, lgbm_train_pred)\n",
        "lgbm_train_f1 = f1_score(y_train, lgbm_train_pred)\n",
        "lgbm_train_roc_auc = roc_auc_score(y_train, lgbm_train_pred_proba)\n",
        "lgbm_train_cm = confusion_matrix(y_train, lgbm_train_pred)\n",
        "lgbm_train_report = classification_report(y_train, lgbm_train_pred)\n",
        "\n",
        "print(\"LightGBM:\")\n",
        "print(\"Training Metrics:\")\n",
        "print(f\"Accuracy: {lgbm_train_accuracy:.4f}\")\n",
        "print(f\"Precision: {lgbm_train_precision:.4f}\")\n",
        "print(f\"Recall: {lgbm_train_recall:.4f}\")\n",
        "print(f\"F1-score: {lgbm_train_f1:.4f}\")\n",
        "print(f\"ROC AUC Score: {lgbm_train_roc_auc:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(lgbm_train_cm)\n",
        "print(\"Training Classification Report:\")\n",
        "print(lgbm_train_report)"
      ],
      "metadata": {
        "id": "OC0pgXgh4sox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.Model Evaluation (Testing Set)"
      ],
      "metadata": {
        "id": "r_ucPomM8V9X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Naive Bayes Classifier\n",
        "\n"
      ],
      "metadata": {
        "id": "DB16m5rLPgtF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nb_test_pred = nb.predict(X_test)\n",
        "nb_test_pred_proba = nb.predict_proba(X_test)[:, 1]\n",
        "nb_test_accuracy = accuracy_score(y_test, nb_test_pred)\n",
        "nb_test_precision = precision_score(y_test, nb_test_pred)\n",
        "nb_test_recall = recall_score(y_test, nb_test_pred)\n",
        "nb_test_f1 = f1_score(y_test, nb_test_pred)\n",
        "nb_test_roc_auc = roc_auc_score(y_test, nb_test_pred_proba)\n",
        "nb_test_cm = confusion_matrix(y_test, nb_test_pred)\n",
        "nb_test_report = classification_report(y_test, nb_test_pred)\n",
        "\n",
        "print(\"Naive Bayes:\")\n",
        "print(\"\\nTesting Metrics:\")\n",
        "print(f\"Accuracy: {nb_test_accuracy:.4f}\")\n",
        "print(f\"Precision: {nb_test_precision:.4f}\")\n",
        "print(f\"Recall: {nb_test_recall:.4f}\")\n",
        "print(f\"F1-score: {nb_test_f1:.4f}\")\n",
        "print(f\"ROC AUC Score: {nb_test_roc_auc:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(nb_test_cm)\n",
        "print(\"Testing Classification Report:\")\n",
        "print(nb_test_report)"
      ],
      "metadata": {
        "id": "y4YbKaeL8ggo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Support Vector Machine"
      ],
      "metadata": {
        "id": "KPr45R8xPo8c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm_test_pred = svm.predict(X_test)\n",
        "svm_train_pred_proba = svm.predict_proba(X_train)[:, 1]\n",
        "svm_test_accuracy = accuracy_score(y_test, svm_test_pred)\n",
        "svm_test_precision = precision_score(y_test, svm_test_pred)\n",
        "svm_test_recall = recall_score(y_test, svm_test_pred)\n",
        "svm_test_f1 = f1_score(y_test, svm_test_pred)\n",
        "svm_test_roc_auc = roc_auc_score(y_test, svm_test_pred_proba)\n",
        "svm_test_cm = confusion_matrix(y_test, svm_test_pred)\n",
        "svm_test_report = classification_report(y_test, svm_test_pred)\n",
        "\n",
        "print(\"SVM:\")\n",
        "print(\"\\nTesting Metrics:\")\n",
        "print(f\"Accuracy: {svm_test_accuracy:.4f}\")\n",
        "print(f\"Precision: {svm_test_precision:.4f}\")\n",
        "print(f\"Recall: {svm_test_recall:.4f}\")\n",
        "print(f\"F1-score: {svm_test_f1:.4f}\")\n",
        "print(f\"ROC AUC Score: {svm_test_roc_auc:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(svm_test_cm)\n",
        "print(\"Testing Classification Report:\")\n",
        "print(svm_test_report)"
      ],
      "metadata": {
        "id": "9zdzTG0p-akx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Logistic Regression"
      ],
      "metadata": {
        "id": "HO04fiuzPwc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_test_pred = lr.predict(X_test)\n",
        "lr_test_pred_proba = lr.predict_proba(X_test)[:, 1]\n",
        "lr_test_accuracy = accuracy_score(y_test, lr_test_pred)\n",
        "lr_test_precision = precision_score(y_test, lr_test_pred)\n",
        "lr_test_recall = recall_score(y_test, lr_test_pred)\n",
        "lr_test_f1 = f1_score(y_test, lr_test_pred)\n",
        "lr_test_roc_auc = roc_auc_score(y_test, lr_test_pred_proba)\n",
        "lr_test_cm = confusion_matrix(y_test, lr_test_pred)\n",
        "lr_test_report = classification_report(y_test, lr_test_pred)\n",
        "\n",
        "print(\"Logistic Regression:\")\n",
        "print(\"\\nTesting Metrics:\")\n",
        "print(f\"Accuracy: {lr_test_accuracy:.4f}\")\n",
        "print(f\"Precision: {lr_test_precision:.4f}\")\n",
        "print(f\"Recall: {lr_test_recall:.4f}\")\n",
        "print(f\"F1-score: {lr_test_f1:.4f}\")\n",
        "print(f\"ROC AUC Score: {lr_test_roc_auc:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(lr_test_cm)\n",
        "print(\"Testing Classification Report:\")\n",
        "print(lr_test_report)"
      ],
      "metadata": {
        "id": "Tmr89oBw-Dzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Random Forest"
      ],
      "metadata": {
        "id": "pttSXXIOPz8X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_test_pred = rf.predict(X_test)\n",
        "rf_test_pred_proba = rf.predict_proba(X_test)[:, 1]\n",
        "rf_test_accuracy = accuracy_score(y_test, rf_test_pred)\n",
        "rf_test_precision = precision_score(y_test, rf_test_pred)\n",
        "rf_test_recall = recall_score(y_test, rf_test_pred)\n",
        "rf_test_f1 = f1_score(y_test, rf_test_pred)\n",
        "rf_test_roc_auc = roc_auc_score(y_test, rf_test_pred_proba)\n",
        "rf_test_cm = confusion_matrix(y_test, rf_test_pred)\n",
        "rf_test_report = classification_report(y_test, rf_test_pred)\n",
        "\n",
        "print(\"Random Forest:\")\n",
        "print(\"\\nTesting Metrics:\")\n",
        "print(f\"Accuracy: {rf_test_accuracy:.4f}\")\n",
        "print(f\"Precision: {rf_test_precision:.4f}\")\n",
        "print(f\"Recall: {rf_test_recall:.4f}\")\n",
        "print(f\"F1-score: {rf_test_f1:.4f}\")\n",
        "print(f\"ROC AUC Score: {rf_test_roc_auc:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(rf_test_cm)\n",
        "print(\"Testing Classification Report:\")\n",
        "print(rf_test_report)"
      ],
      "metadata": {
        "id": "9Zj-eY2S9yTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* LightGBM"
      ],
      "metadata": {
        "id": "mGeN4ec5P220"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_test_pred = lgbm.predict(X_test)\n",
        "lgbm_test_pred_proba = lgbm.predict_proba(X_test)[:, 1]\n",
        "lgbm_test_accuracy = accuracy_score(y_test, lgbm_test_pred)\n",
        "lgbm_test_precision = precision_score(y_test, lgbm_test_pred)\n",
        "lgbm_test_recall = recall_score(y_test, lgbm_test_pred)\n",
        "lgbm_test_f1 = f1_score(y_test, lgbm_test_pred)\n",
        "lgbm_test_roc_auc = roc_auc_score(y_test, lgbm_test_pred_proba)\n",
        "lgbm_test_cm = confusion_matrix(y_test, lgbm_test_pred)\n",
        "lgbm_test_report = classification_report(y_test, lgbm_test_pred)\n",
        "\n",
        "print(\"LightGBM:\")\n",
        "print(\"\\nTesting Metrics:\")\n",
        "print(f\"Accuracy: {lgbm_test_accuracy:.4f}\")\n",
        "print(f\"Precision: {lgbm_test_precision:.4f}\")\n",
        "print(f\"Recall: {lgbm_test_recall:.4f}\")\n",
        "print(f\"F1-score: {lgbm_test_f1:.4f}\")\n",
        "print(f\"ROC AUC Score: {lgbm_test_roc_auc:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(lgbm_test_cm)\n",
        "print(\"Testing Classification Report:\")\n",
        "print(lgbm_test_report)"
      ],
      "metadata": {
        "id": "MALdnjkF9mdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9.Deployment"
      ],
      "metadata": {
        "id": "C7y7kMalQ08W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the CountVectorizer to the training data and save it\n",
        "cv.fit(train_upsampled['tweet'])\n",
        "with open('model_and_cv.pkl', 'wb') as file:\n",
        "    pickle.dump((rf, cv), file)"
      ],
      "metadata": {
        "id": "Gr1OAp5lyXEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained model and CountVectorizer object\n",
        "with open('model_and_cv.pkl', 'rb') as file:\n",
        "    model, cv = pickle.load(file)\n",
        "\n",
        "# Enter input text\n",
        "input_text = \"<input your text here>\"\n",
        "\n",
        "# Preprocess the input text\n",
        "clean_input_text = clean_text(input_text)\n",
        "\n",
        "# Vectorize the input text using the same CountVectorizer object used during training\n",
        "vectorized_input = cv.transform([clean_input_text])\n",
        "\n",
        "# Make predictions\n",
        "prediction = model.predict(vectorized_input)\n",
        "print(prediction)\n",
        "# Interpret the results\n",
        "if prediction == 1:\n",
        "    print(\"The input text contains hate speech.\")\n",
        "else:\n",
        "    print(\"The input text does not contain hate speech.\")\n"
      ],
      "metadata": {
        "id": "fVfhixtO6IwH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}